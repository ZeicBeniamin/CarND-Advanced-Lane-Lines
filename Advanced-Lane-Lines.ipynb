{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points like (0,0,0), (1,0,0), (2,0,0), ...,(6,5,0)\n",
    "objpts = np.zeros((6*9, 3), np.float32)\n",
    "# Get the meshgrid points one by one and replace them in the x and y \n",
    "# coordinates of the object points\n",
    "objpts[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "def get_cam_params():\n",
    "    '''\n",
    "    Gets undistortion parameters for the camera, based on a set of calibration images\n",
    "    \n",
    "    Takes all the images in the `camera_cal` folder and finds the undistortion coefficients based\n",
    "    on the images.\n",
    "    The calibration matrix and dist parameters are the only things we will use later on.\n",
    "    \n",
    "    :return: Camera parameters, namely `mtx` and `dist`\n",
    "    \n",
    "    '''\n",
    "    images = glob.glob('camera_cal/*.jpg')\n",
    "\n",
    "    for idx, frame_name in enumerate(images):\n",
    "        image = cv2.imread(frame_name)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        if ret == True:\n",
    "            objpoints.append(objpts)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "\n",
    "            cv2.imshow('image', image)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "    test_img = cv2.imread('camera_cal/calibration4.jpg')\n",
    "    imshape = test_img.shape\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (imshape[1], imshape[0]), None, None)\n",
    "\n",
    "    result = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('camera_cal/test_undist.jpg', result)\n",
    "    \n",
    "    return mtx, dist\n",
    "    \n",
    "    \n",
    "def store_cam_params(mtx, dist):\n",
    "    '''\n",
    "    Stores the two camera parameters as a binary file for later use\n",
    "    \n",
    "    :param mtx: Transformation matrix to store in the pickle file\n",
    "    :param dist: Parameter containing distances, to store in the pickle file\n",
    "    \n",
    "    '''\n",
    "    pkl = {}\n",
    "    pkl[\"mtx\"] = mtx\n",
    "    pkl[\"dist\"] = dist\n",
    "    pickle.dump( pkl, open( \"camera_cal/camera_param_pickle.p\", \"wb\" ) )\n",
    "    \n",
    "def load_pickle():\n",
    "    '''\n",
    "    Loads the camera parameters from the pickle file previously stored.\n",
    "    \n",
    "    :return: Dictionary containg the data in pickle\n",
    "    \n",
    "    '''\n",
    "    infile = open(\"camera_cal/camera_param_pickle.p\",'rb')\n",
    "    new_dict = pickle.load(infile)\n",
    "    infile.close()\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_select(image, thresh=(0, 255), channel='l'):\n",
    "    '''\n",
    "    Masks the given channel of the CIE Lab image using the thresholds given.\n",
    "    \n",
    "    :param image: Image to be converted in CIE Lab and then thresholded\n",
    "    :param thresh: Tuple containing upper and lower threshold values\n",
    "    :param channel: Character indicating the channel to work on\n",
    "    :return: The thresholded binary image\n",
    "    \n",
    "    '''\n",
    "    # Convert the image to the CIE Lab colorspace\n",
    "    cie_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "#     cie_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Select the appropriate channel for processing\n",
    "    if channel == 'l':\n",
    "        ch = 0\n",
    "        channel = \"CIE L\"\n",
    "    elif channel == 'a':\n",
    "        ch = 1\n",
    "        channel = \"CIE A\"\n",
    "    elif channel == 'b':\n",
    "        ch = 2\n",
    "        channel = \"CIE B\"\n",
    "\n",
    "    layer = cie_lab[:, :, ch]\n",
    "    \n",
    "    # The L channel has an automatic thresholding mode, regardles of the input thresholds\n",
    "    if channel == 'CIE L':\n",
    "        \n",
    "        a = 39.20193\n",
    "        b= 5.121302\n",
    "        c = 42.48095\n",
    "        d = 88.16211\n",
    "\n",
    "        avg = np.average(layer[420:,:])\n",
    "        \n",
    "        thresh0 = d + (a - d) / (1 + (avg / c) ** b)\n",
    "        thresh0 = thresh0\n",
    "        thresh1 = 100\n",
    "\n",
    "    else:\n",
    "        thresh0 = thresh[0]\n",
    "        thresh1 = thresh[1]\n",
    "        \n",
    "    # Return a binary image of threshold result\n",
    "    mask = np.zeros_like(layer)\n",
    "    \n",
    "    mask[(layer >= thresh0) & (layer <= thresh1)] = 1\n",
    "    \n",
    "    \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_filters(image):\n",
    "    '''\n",
    "    Combine different filters in order to get the lanes from the image.\n",
    "    \n",
    "    :param image: Image to process\n",
    "    :return: Binary mask of the image with everything but the lane lines removed\n",
    "    \n",
    "    '''\n",
    "    # Parameters for the bilateral filter\n",
    "    diam = 9\n",
    "    sig_col = 13\n",
    "    sig_sp = 31\n",
    "\n",
    "    \n",
    "    blur_filter = cv2.bilateralFilter(image, d=diam, sigmaColor=sig_col, sigmaSpace=sig_sp)\n",
    "\n",
    "    # Take two masked images, applying different thresholds on each of them\n",
    "    # The cie_l image automatically calculates it's thresholds\n",
    "    cie_l = lab_select(blur_filter)\n",
    "    cie_b = lab_select(blur_filter, (18, 100), \"b\")\n",
    "    \n",
    "    # Combine the two images in a single one\n",
    "    combined = np.zeros_like(cie_l)\n",
    "    combined[(cie_l == 1) | (cie_b == 1)] = 1\n",
    "    \n",
    "#     return np.dstack((combined, combined, combined))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_image(image):\n",
    "    '''\n",
    "    Convert the image to another format, apply the filtering function and convert it back to the original format\n",
    "    \n",
    "    :param image: Image to process\n",
    "    :return: Processed image of type uint8\n",
    "    \n",
    "    '''\n",
    "    # Convert image from float32 to uint8\n",
    "    image = image.astype(np.float32)\n",
    "    image = image/255\n",
    "\n",
    "        \n",
    "    # Send the image for processing to combined_image()\n",
    "    comb = combined_filters(image)\n",
    "\n",
    "    # Convert the image back to uint8\n",
    "#     weighted = cv2.addWeighted(image, 0.5, comb, 1, 0)\n",
    "    \n",
    "    weighted = comb\n",
    "    uint_img = cv2.convertScaleAbs(weighted * 255)\n",
    "    \n",
    "    return uint_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def undistort(image, mtx, dist):\n",
    "    ''' Undistorts given image based on the parameters `mtx` adn `dist`'''\n",
    "    \n",
    "    result = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_perspective(image, mode=\"direct\"):\n",
    "    '''\n",
    "    Transform the image in bird's eye view or from bird's eye view back to normal\n",
    "    \n",
    "    :param image: Image to process\n",
    "    :mode: String indicating if the transformation is a direct or inverse one\n",
    "    :return: Perspective transformed image\n",
    "    \n",
    "    '''\n",
    "    height = image.shape[0]\n",
    "    width  = image.shape[1]\n",
    "    \n",
    "    # Set the horizontal boundaries of the roi to be warped\n",
    "    y1 = 450\n",
    "    y2 = 690\n",
    "\n",
    "    coef = 300\n",
    "    up = 33\n",
    "\n",
    "    pts1 = np.float32([[587 - up, y1], [692 + up,  y1], [1068 + coef,      y2], [230 - coef,   y2]])\n",
    "    pts2 = np.float32([[0,    0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "    if mode == \"direct\":\n",
    "        M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(pts2, pts1)\n",
    "\n",
    "    # Transform the image\n",
    "    dst = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped, draw_boxes=False):\n",
    "\n",
    "    # Apply this operations on a warped binary image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:, :], axis=0)\n",
    "    # Create an output image, to visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # print(leftx_base, \" \", rightx_base)\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set width of windows +/- margin\n",
    "    margin = 100\n",
    "    # Minimum number of pixels to recenter image\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on the parameters above\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    # NOTE: np.nonzero() returns the indices of the nonzero points in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    \n",
    "    # Split the array of nonzero points in two arrays that contain only the x and y \n",
    "    # coordinates respectively\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Set the current position to be the base of the first window. The position will be \n",
    "    # updated for each window in `nwindows`\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "\n",
    "        win_xleft_low   = leftx_current - margin\n",
    "        win_xleft_high  = leftx_current + margin\n",
    "        win_xright_low  = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        if draw_boxes:\n",
    "            cv2.rectangle(out_img, (win_xleft_low, win_y_low),\n",
    "                          (win_xleft_high, win_y_high), (0,255,0), 2)\n",
    "            cv2.rectangle(out_img, (win_xright_low, win_y_low),\n",
    "                          (win_xright_high, win_y_high), (0,255,0), 2)\n",
    "\n",
    "        # TODO: Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = np.array(np.nonzero((win_xleft_low <= nonzerox) & (nonzerox < win_xleft_high) &\n",
    "                                             (win_y_low <= nonzeroy) & (nonzeroy < win_y_high)))\n",
    "        # good_left_inds = nonzerox[(win_xleft_low < nonzerox) & (nonzerox < win_xleft_high) &\n",
    "        #                           (win_y_low < nonzeroy) & (nonzeroy < win_y_high)]\n",
    "        good_right_inds = np.array(np.nonzero((win_xright_low <= nonzerox) & (nonzerox < win_xright_high) &\n",
    "                                              (win_y_low <= nonzeroy) & (nonzeroy < win_y_high)))\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds[0])\n",
    "        right_lane_inds.append(good_right_inds[0])\n",
    "\n",
    "        # TODO: If you found > minpix pixels, recenter window\n",
    "        # (`right` or `leftx_current`) on their mean position\n",
    "\n",
    "        if (np.size(good_right_inds) > minpix):\n",
    "            rightx_current = np.int(np.average(nonzerox[good_right_inds], axis=1))\n",
    "\n",
    "        if (np.size(good_left_inds) > minpix):\n",
    "            leftx_current = np.int(np.average(nonzerox[good_left_inds], axis=1))\n",
    "            # print(leftx_current)\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    \n",
    "    ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "    \n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    try:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    except:\n",
    "        print(\"Points vector is empty\")\n",
    "        left_fit = [0,0,0]\n",
    "        right_fit = [0,0,0]\n",
    "    \n",
    "#     left_fit = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "#     right_fit = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    \n",
    "#     right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix , 2)\n",
    "    \n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    # np.linspace() is similar to range(first, last, values), with the difference that the last parameters specifies the\n",
    "    # number of values to be generated, not the step\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "\n",
    "    # Generate the x coordinates for each of the y coordinates of the fitted function\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    except:\n",
    "        print(\"The function failed to fit a line!\")\n",
    "\n",
    "    ### Visualization\n",
    "    # Colors in the left an right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "#     for x, y, xx in zip(left_fitx, ploty, right_fitx):\n",
    "#         y = int(y)\n",
    "#         x = int(x)\n",
    "#         xx = int(xx)\n",
    "        \n",
    "#         cv2.circle(out_img, (x,y), 5, (50, 150, 255))\n",
    "#         cv2.circle(out_img, (xx,y), 5, (50, 150, 255))\n",
    "        \n",
    "    return out_img, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(left_fit_cr, right_fit_cr):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = 719\n",
    "    \n",
    "    left_fit_0 = left_fit_cr[0] * (xm_per_pix/(ym_per_pix ** 2))\n",
    "    left_fit_1 = left_fit_cr[1] * (xm_per_pix/ym_per_pix)\n",
    "    \n",
    "    right_fit_0 = right_fit_cr[0] * (xm_per_pix/(ym_per_pix ** 2))\n",
    "    right_fit_1 = right_fit_cr[1] * (xm_per_pix/ym_per_pix)\n",
    "\n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad =  ((1 + (2 * left_fit_0 * y_eval * ym_per_pix + left_fit_1) ** 2) ** (3/2)) / np.abs(2 * left_fit_0)\n",
    "    right_curverad = ((1 + (2 * right_fit_0 * y_eval * ym_per_pix + right_fit_1) ** 2) ** (3/2)) / np.abs(2 * right_fit_0)\n",
    "\n",
    "    return left_curverad, right_curverad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_images/7.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Warping works'''\n",
    "\n",
    "params_dict = load_pickle()\n",
    "\n",
    "image = cv2.imread('test_images/2.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "undist = undistort(image, params_dict[\"mtx\"], params_dict[\"dist\"])\n",
    "warped = warp_perspective(undist)\n",
    "\n",
    "# res = np.vstack((image, undist))\n",
    "\n",
    "# res = cv2.resize(res, (res.shape[1]//2,res.shape[0]//2))\n",
    "cv2.imshow('res', warped)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imwrite('output_images/camera_cal_before.png', image)\n",
    "# cv2.imwrite('output_images/camera_cal_after.png', undist)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_lane(masked_img, left_fit, right_fit):\n",
    "    '''\n",
    "    Fills the space in between the two lane lines with a color\n",
    "    \n",
    "    :param masked_img: Image that will be modified\n",
    "    :param left_fit: The coefficients of the left lane\n",
    "    :param right_fit: The coefficients of the right lane\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Get an array of numbers from 0 to the height of the image (720 in our case)\n",
    "    ploty = np.linspace(0, masked_img.shape[0] - 1, masked_img.shape[0])\n",
    "    \n",
    "    # Try fitting a polynomial on the lane\n",
    "    try:\n",
    "        left_x = left_fit[0] * (ploty ** 2) + left_fit[1] * ploty + left_fit[2]\n",
    "        left_lane = np.stack((left_x, ploty), -1)\n",
    "\n",
    "        ploty = ploty[::-1]\n",
    "        \n",
    "        right_x = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "        right_lane = np.stack((right_x, ploty), -1)\n",
    "        \n",
    "        polygon = np.concatenate((left_lane, right_lane))\n",
    "        polygon = np.int32([polygon])\n",
    "\n",
    "        cv2.fillPoly(masked_img, polygon, (51, 255, 102))\n",
    "    except:\n",
    "        print(\"Error drawing the lane\")\n",
    "    \n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_offset(img_shape, left_fit, right_fit):\n",
    "    '''\n",
    "    Calculates the offset from the center of the lane\n",
    "    \n",
    "    :param img_shape: The shape of the image received from the camera\n",
    "    :param left_fit: Coefficients of the left lane polynomial\n",
    "    :param right_fit: Coefficients of the right lane polynomial\n",
    "    :return: A number representing the offset measured in meters\n",
    "\n",
    "    '''\n",
    "    # The camera that takes the images is centered, so the center of the image corresponds to\n",
    "    # the center of the car\n",
    "    img_center = img_shape[1]//2\n",
    "    \n",
    "    # Calculate the values of both polynomials at the bottom of the image (i.e. nearest to the car)\n",
    "    y = 719\n",
    "\n",
    "    left_pos  = left_fit[0] * (y ** 2) + left_fit[1] * y + left_fit[2]\n",
    "    right_pos = right_fit[0] * (y ** 2) + right_fit[1] * y + right_fit[2]\n",
    "    \n",
    "    # Find the center of the lane and the offset measured in pixels\n",
    "    lane_center = (left_pos + right_pos)/2\n",
    "    offset_pix = lane_center - img_center\n",
    "    \n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Convert that offset in meters\n",
    "    offset_met = xm_per_pix * offset_pix\n",
    "    \n",
    "    return offset_met\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16590379061350496\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test_images/3.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "''' Camera undistortion works '''\n",
    "\n",
    "''' IMportant code lines below'''\n",
    "# mtx, dist = get_cam_params()\n",
    "# store_cam_params(mtx, dist)\n",
    "params_dict = load_pickle()\n",
    "\n",
    "def process_image(image):\n",
    "\n",
    "    undist = undistort(image, params_dict[\"mtx\"], params_dict[\"dist\"])\n",
    "    binary = filtered_image(undist)\n",
    "    warped = warp_perspective(binary)\n",
    "    fit, left_fit, right_fit    = fit_polynomial(warped)\n",
    "    radius = measure_curvature_real(left_fit, right_fit)\n",
    "\n",
    "    offset = calculate_offset(image.shape, left_fit, right_fit)\n",
    "    \n",
    "    filled = fill_lane(fit, left_fit, right_fit)\n",
    "    \n",
    "    unwarped = warp_perspective(filled, \"inverse\")\n",
    "    \n",
    "    weighted = cv2.addWeighted(image, 1, unwarped, 0.5, 0)\n",
    "    \n",
    "    print(offset)\n",
    "    \n",
    "    return weighted\n",
    "    \n",
    "final = process_image(image)\n",
    "\n",
    "cv2.imshow('fil', final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRamane pe maine de implementat clasa Lane, cu functionalitatea ei.\\nAm vrut sa pun conversia din pixeli in metri mai sus, in polyfit, dar n-am putut, din cauza ca\\nnp.polyfit e utilizata si pentru desenarea benzii pe imagine, iar daca o convertesc in metri, e bai, \\nliniile de fit ies din imagine.\\nAm pus conversia doar la calcularea razei, dar banuiesc ca rezultatele nu-s bune. :)\\n\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Facui lucrurile cerute mai jos '''\n",
    "\"\"\"\n",
    "Ramane pe maine de implementat clasa Lane, cu functionalitatea ei.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Coming up....\\n\\n    - bird's eye view\\n    - indentify lanes (customize the aalgorithm a little)\\n    - gather lane points (start with box, continue from prior)\\n                          check for boxes touching edge\\n    - fit polynomial on lanes\\n    - calculate the radius\\n    \\n    \\n    - implement a Lane class \\n        (with history, averaging over n previous values, outlier rejection - based on \\n        polynomial parameters variation or radius variation)\\n        + reset method for deeply flawed measurements\\n        \\n    - apply all of it on the video\\n\\n\\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Coming up....\n",
    "\n",
    "    - bird's eye view\n",
    "    - indentify lanes (customize the aalgorithm a little)\n",
    "    - gather lane points (start with box, continue from prior)\n",
    "                          check for boxes touching edge\n",
    "    - fit polynomial on lanes\n",
    "    - calculate the radius\n",
    "    \n",
    "    \n",
    "    - implement a Lane class \n",
    "        (with history, averaging over n previous values, outlier rejection - based on \n",
    "        polynomial parameters variation or radius variation)\n",
    "        + reset method for deeply flawed measurements\n",
    "        \n",
    "    - apply all of it on the video\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \n",
      "\n",
      "\u001b[A\u001b[A                                                      \n",
      "t:   1%|▏         | 7/485 [1:18:18<00:48,  9.77it/s, now=None]\n",
      "\n",
      "t:   1%|▏         | 7/485 [1:14:48<00:55,  8.66it/s, now=None]\u001b[A\u001b[A\n",
      "                                                              \u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                        \n",
      "t:   1%|▏         | 7/485 [1:18:18<00:48,  9.77it/s, now=None]\n",
      "\n",
      "t:   1%|▏         | 7/485 [1:14:48<00:55,  8.66it/s, now=None]\u001b[A\u001b[A\n",
      "t:   1%|▏         | 7/485 [1:17:11<00:51,  9.24it/s, now=None]\u001b[A\n",
      "\n",
      "\n",
      "t:   0%|          | 0/125 [00:00<?, ?it/s, now=None]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/project_video.mp4.\n",
      "Moviepy - Writing video test_videos_output/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "t:   2%|▏         | 2/125 [00:00<00:10, 11.99it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 3/125 [00:00<00:13,  9.14it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 4/125 [00:00<00:14,  8.60it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   4%|▍         | 5/125 [00:00<00:14,  8.01it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   5%|▍         | 6/125 [00:00<00:15,  7.72it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   6%|▌         | 7/125 [00:00<00:15,  7.80it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   6%|▋         | 8/125 [00:01<00:14,  7.92it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   7%|▋         | 9/125 [00:01<00:14,  7.93it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   8%|▊         | 10/125 [00:01<00:14,  7.93it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:   9%|▉         | 11/125 [00:01<00:14,  8.01it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  10%|▉         | 12/125 [00:01<00:14,  8.07it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  10%|█         | 13/125 [00:01<00:13,  8.07it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  11%|█         | 14/125 [00:01<00:13,  8.06it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  12%|█▏        | 15/125 [00:01<00:13,  7.99it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  13%|█▎        | 16/125 [00:02<00:13,  7.79it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  14%|█▎        | 17/125 [00:02<00:14,  7.63it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  14%|█▍        | 18/125 [00:02<00:14,  7.62it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  15%|█▌        | 19/125 [00:02<00:14,  7.47it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  16%|█▌        | 20/125 [00:02<00:13,  7.52it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  17%|█▋        | 21/125 [00:02<00:14,  7.33it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  18%|█▊        | 22/125 [00:02<00:14,  7.27it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  18%|█▊        | 23/125 [00:02<00:13,  7.49it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  19%|█▉        | 24/125 [00:03<00:13,  7.52it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  20%|██        | 25/125 [00:03<00:13,  7.61it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  21%|██        | 26/125 [00:03<00:13,  7.47it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  22%|██▏       | 27/125 [00:03<00:13,  7.33it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  22%|██▏       | 28/125 [00:03<00:13,  7.37it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  23%|██▎       | 29/125 [00:03<00:12,  7.44it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  24%|██▍       | 30/125 [00:03<00:12,  7.33it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  25%|██▍       | 31/125 [00:04<00:12,  7.24it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  26%|██▌       | 32/125 [00:04<00:12,  7.29it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  26%|██▋       | 33/125 [00:04<00:12,  7.17it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  27%|██▋       | 34/125 [00:04<00:13,  6.98it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  28%|██▊       | 35/125 [00:04<00:13,  6.86it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  29%|██▉       | 36/125 [00:04<00:12,  6.86it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  30%|██▉       | 37/125 [00:04<00:13,  6.67it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  30%|███       | 38/125 [00:05<00:13,  6.54it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  31%|███       | 39/125 [00:05<00:13,  6.44it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  32%|███▏      | 40/125 [00:05<00:13,  6.33it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  33%|███▎      | 41/125 [00:05<00:13,  6.10it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  34%|███▎      | 42/125 [00:05<00:14,  5.81it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  34%|███▍      | 43/125 [00:05<00:14,  5.55it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  35%|███▌      | 44/125 [00:06<00:15,  5.25it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  36%|███▌      | 45/125 [00:06<00:15,  5.29it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  37%|███▋      | 46/125 [00:06<00:15,  5.26it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  38%|███▊      | 47/125 [00:06<00:15,  5.09it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  38%|███▊      | 48/125 [00:06<00:15,  5.07it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  39%|███▉      | 49/125 [00:07<00:14,  5.08it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  40%|████      | 50/125 [00:07<00:14,  5.11it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  41%|████      | 51/125 [00:07<00:15,  4.91it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  42%|████▏     | 52/125 [00:07<00:15,  4.65it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  42%|████▏     | 53/125 [00:08<00:15,  4.70it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  43%|████▎     | 54/125 [00:08<00:14,  4.82it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  44%|████▍     | 55/125 [00:08<00:14,  4.87it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  45%|████▍     | 56/125 [00:08<00:13,  5.11it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  46%|████▌     | 57/125 [00:08<00:13,  5.17it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  46%|████▋     | 58/125 [00:08<00:12,  5.56it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  47%|████▋     | 59/125 [00:09<00:11,  5.66it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  48%|████▊     | 60/125 [00:09<00:10,  6.20it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  49%|████▉     | 61/125 [00:09<00:09,  6.51it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  50%|████▉     | 62/125 [00:09<00:09,  6.86it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  50%|█████     | 63/125 [00:09<00:08,  6.91it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  51%|█████     | 64/125 [00:09<00:08,  6.89it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  52%|█████▏    | 65/125 [00:09<00:08,  6.88it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  53%|█████▎    | 66/125 [00:10<00:08,  7.11it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  54%|█████▎    | 67/125 [00:10<00:07,  7.46it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  54%|█████▍    | 68/125 [00:10<00:07,  7.66it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  55%|█████▌    | 69/125 [00:10<00:07,  7.86it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  56%|█████▌    | 70/125 [00:10<00:06,  8.24it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  57%|█████▋    | 71/125 [00:10<00:06,  8.56it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  58%|█████▊    | 72/125 [00:10<00:07,  7.56it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  58%|█████▊    | 73/125 [00:11<00:08,  6.28it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  59%|█████▉    | 74/125 [00:11<00:08,  5.80it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  60%|██████    | 75/125 [00:11<00:09,  5.51it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  61%|██████    | 76/125 [00:11<00:09,  5.38it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  62%|██████▏   | 77/125 [00:11<00:09,  5.20it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  62%|██████▏   | 78/125 [00:12<00:09,  5.21it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  63%|██████▎   | 79/125 [00:12<00:08,  5.26it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  64%|██████▍   | 80/125 [00:12<00:07,  5.95it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  65%|██████▍   | 81/125 [00:12<00:06,  6.49it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  66%|██████▌   | 82/125 [00:12<00:06,  7.07it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  66%|██████▋   | 83/125 [00:12<00:05,  7.64it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  67%|██████▋   | 84/125 [00:12<00:05,  8.10it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  68%|██████▊   | 85/125 [00:12<00:04,  8.28it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  69%|██████▉   | 86/125 [00:13<00:05,  7.13it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  70%|██████▉   | 87/125 [00:13<00:05,  6.45it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  70%|███████   | 88/125 [00:13<00:05,  6.26it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  71%|███████   | 89/125 [00:13<00:05,  6.91it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  72%|███████▏  | 90/125 [00:13<00:04,  7.48it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  73%|███████▎  | 91/125 [00:13<00:04,  7.94it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  74%|███████▎  | 92/125 [00:13<00:04,  8.15it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  74%|███████▍  | 93/125 [00:14<00:03,  8.44it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  75%|███████▌  | 94/125 [00:14<00:03,  8.66it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  76%|███████▌  | 95/125 [00:14<00:03,  8.87it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  77%|███████▋  | 96/125 [00:14<00:03,  8.88it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  78%|███████▊  | 97/125 [00:14<00:03,  8.76it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  78%|███████▊  | 98/125 [00:14<00:03,  7.27it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  79%|███████▉  | 99/125 [00:14<00:03,  7.59it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  80%|████████  | 100/125 [00:14<00:03,  7.98it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  81%|████████  | 101/125 [00:15<00:03,  7.62it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  82%|████████▏ | 102/125 [00:15<00:03,  6.70it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  82%|████████▏ | 103/125 [00:15<00:03,  6.85it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  83%|████████▎ | 104/125 [00:15<00:02,  7.29it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  84%|████████▍ | 105/125 [00:15<00:02,  7.68it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  85%|████████▍ | 106/125 [00:15<00:02,  8.04it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  86%|████████▌ | 107/125 [00:15<00:02,  8.32it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  86%|████████▋ | 108/125 [00:15<00:02,  8.50it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  87%|████████▋ | 109/125 [00:16<00:01,  8.69it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  88%|████████▊ | 110/125 [00:16<00:01,  8.83it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  89%|████████▉ | 111/125 [00:16<00:01,  8.79it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  90%|████████▉ | 112/125 [00:16<00:01,  8.58it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  90%|█████████ | 113/125 [00:16<00:01,  8.64it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  91%|█████████ | 114/125 [00:16<00:01,  8.70it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  92%|█████████▏| 115/125 [00:16<00:01,  8.77it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  93%|█████████▎| 116/125 [00:16<00:01,  8.70it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  94%|█████████▎| 117/125 [00:16<00:00,  8.69it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  94%|█████████▍| 118/125 [00:17<00:00,  8.81it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  95%|█████████▌| 119/125 [00:17<00:00,  8.90it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  96%|█████████▌| 120/125 [00:17<00:00,  8.94it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  97%|█████████▋| 121/125 [00:17<00:00,  8.62it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  98%|█████████▊| 122/125 [00:17<00:00,  8.79it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  98%|█████████▊| 123/125 [00:17<00:00,  8.89it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t:  99%|█████████▉| 124/125 [00:17<00:00,  8.87it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "t: 100%|██████████| 125/125 [00:17<00:00,  8.85it/s, now=None]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                              \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                        \n",
      "t:   1%|▏         | 7/485 [1:18:36<00:48,  9.77it/s, now=None]\n",
      "\n",
      "t:   1%|▏         | 7/485 [1:15:07<00:55,  8.66it/s, now=None]\u001b[A\u001b[A\n",
      "                                                              \u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                        \n",
      "t:   1%|▏         | 7/485 [1:18:36<00:48,  9.77it/s, now=None]\n",
      "\n",
      "t:   1%|▏         | 7/485 [1:15:07<00:55,  8.66it/s, now=None]\u001b[A\u001b[A\n",
      "t:   1%|▏         | 7/485 [1:17:30<00:51,  9.24it/s, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/project_video.mp4\n",
      "CPU times: user 1min 3s, sys: 1.81 s, total: 1min 5s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(20,25)\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenvpi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
