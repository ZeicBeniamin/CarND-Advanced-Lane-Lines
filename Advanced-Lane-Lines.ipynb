{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points like (0,0,0), (1,0,0), (2,0,0), ...,(6,5,0)\n",
    "objpts = np.zeros((6*9, 3), np.float32)\n",
    "# Get the meshgrid points one by one and replace them in the x and y \n",
    "# coordinates of the object points\n",
    "objpts[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "def get_cam_params():\n",
    "    images = glob.glob('camera_cal/*.jpg')\n",
    "\n",
    "    for idx, frame_name in enumerate(images):\n",
    "        image = cv2.imread(frame_name)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        if ret == True:\n",
    "            objpoints.append(objpts)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "\n",
    "            cv2.imshow('image', image)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "    test_img = cv2.imread('camera_cal/calibration4.jpg')\n",
    "    imshape = test_img.shape\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (imshape[1], imshape[0]), None, None)\n",
    "\n",
    "    result = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('camera_cal/test_undist.jpg', result)\n",
    "    \n",
    "    return mtx, dist\n",
    "    \n",
    "def store_cam_params(mtx, dist):\n",
    "    # Acts like a dictionary that will be saved later using pickle\n",
    "    pkl = {}\n",
    "    pkl[\"mtx\"] = mtx\n",
    "    pkl[\"dist\"] = dist\n",
    "    pickle.dump( pkl, open( \"camera_cal/camera_param_pickle.p\", \"wb\" ) )\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtx, dist = get_cam_params()\n",
    "# store_cam_params(mtx, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img,  thresh=(0, 255), orient='x', sobel_kernel=5):\n",
    "    '''\n",
    "    Calculate directional gradient.\n",
    "    '''\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if orient == 'x':\n",
    "        sobel_dir = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel_dir = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    sobel_abs = np.absolute(sobel_dir)\n",
    "\n",
    "    max_sobel = np.max(sobel_abs)\n",
    "    scaled = np.uint8(255*(sobel_abs/max_sobel))\n",
    "\n",
    "    grad_binary = np.zeros_like(scaled)\n",
    "    grad_binary [(scaled > thresh[0]) & (scaled < thresh[1])] = 1\n",
    "\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, mag_thresh=(0, 255), sobel_kernel=3):\n",
    "    '''Calculate gradient magnitude'''\n",
    "\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude\n",
    "    magnitude = np.sqrt((sobel_x ** 2) + (sobel_y ** 2))\n",
    "\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled = np.uint8(magnitude * 255 / np.max(magnitude))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    mag_binary = np.zeros_like(scaled)\n",
    "    mag_binary[(scaled > mag_thresh[0]) & (scaled < mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, thresh=(0, np.pi/2), sobel_kernel=3):\n",
    "    '''Calculate gradient direction'''\n",
    "\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    absx = np.absolute(sobelx)\n",
    "    absy = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    direction = np.arctan2(absy, absx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    dir_binary = np.zeros_like(direction)\n",
    "    dir_binary[(direction > thresh[0]) & (direction < thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "\n",
    "    return dir_binary\n",
    "\n",
    "def hls_select(imag, thresh=(0, 1), channel='s'):\n",
    "\n",
    "    hls = cv2.cvtColor(imag, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    if channel == 'h':\n",
    "        ch = 0\n",
    "    elif channel == 'l':\n",
    "        ch = 1\n",
    "    else:\n",
    "        ch = 2\n",
    "\n",
    "    layer = hls[:, :, ch]\n",
    "\n",
    "    # 3) Return a binary image of threshold result\n",
    "    mask = np.zeros_like(layer)\n",
    "    # mask = mask * 200\n",
    "\n",
    "    mask[(layer >= thresh[0]) & (layer <= thresh[1])] = 1\n",
    "\n",
    "    # porcarie(thresh, channel)\n",
    "\n",
    "    # print(channel, thresh[0], thresh[1], np.where(layer<1)[1].shape)\n",
    "    # print(np.average(mask), np.max(layer))\n",
    "\n",
    "    return mask\n",
    "\n",
    "def lab_select(image, thresh=(0, 255), channel='l'):\n",
    "\n",
    "#     image = image.astype(np.float32)\n",
    "#     image = image/255\n",
    "    \n",
    "    cie_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    if channel == 'l':\n",
    "        ch = 0\n",
    "        channel = \"CIE L\"\n",
    "    elif channel == 'a':\n",
    "        ch = 1\n",
    "        channel = \"CIE A\"\n",
    "    elif channel == 'b':\n",
    "        ch = 2\n",
    "        channel = \"CIE B\"\n",
    "\n",
    "    layer = cie_lab[:, :, ch]\n",
    "    \n",
    "\n",
    "#     print(layer.dtype)\n",
    "#     print(np.max(layer))\n",
    "\n",
    "    if channel == 'CIE L':\n",
    "#         print(\"Recalculated thresholds\")\n",
    "        \n",
    "        a = 39.20193\n",
    "        b= 5.121302\n",
    "        c = 42.48095\n",
    "        d = 88.16211\n",
    "\n",
    "        avg = np.average(layer[420:,:])\n",
    "        \n",
    "        # y = 88.16211 + (39.20193 - 88.16211) / (1 + (x / 42.48095) ^ 5.121302)\n",
    "        \n",
    "        thresh0 = d + (a - d) / (1 + (avg / c) ** b)\n",
    "        thresh0 = thresh0\n",
    "        thresh1 = 100\n",
    "#         print(channel, \"\\t\", avg, \"\\t thres:\", thresh0)\n",
    "\n",
    "    else:\n",
    "        thresh0 = thresh[0]\n",
    "        thresh1 = thresh[1]\n",
    "        \n",
    "#     print(channel)\n",
    "#     print(np.min(layer))\n",
    "\n",
    "    # 3) Return a binary image of threshold result\n",
    "    mask = np.zeros_like(layer)\n",
    "    \n",
    "    mask[(layer >= thresh0) & (layer <= thresh1)] = 1\n",
    "    \n",
    "#     cv2.imshow('img', mask)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_image(image):\n",
    "    \n",
    "    sobel_low = 20\n",
    "    sobel_high = 255\n",
    "    mag_low = 40\n",
    "    mag_high = 255\n",
    "    \n",
    "    white_low = 8\n",
    "    white_high = 86\n",
    "    yellow_low = 3\n",
    "    yellow_high = 255\n",
    "    \n",
    "    lum_low = 0.72 * 255\n",
    "    lum_high = 1 * 255\n",
    "    sat_low = 0.26 * 255\n",
    "    sat_high = 1 * 244\n",
    "    \n",
    "    diam = 9\n",
    "    sig_col = 13\n",
    "    sig_sp = 31\n",
    "\n",
    "    \n",
    "    blur_filter = cv2.bilateralFilter(image, d=diam, sigmaColor=sig_col, sigmaSpace=sig_sp)\n",
    "\n",
    "    cie_l = lab_select(blur_filter)\n",
    "    cie_b = lab_select(blur_filter, (18, 100), \"b\")\n",
    "    \n",
    "    combined = np.zeros_like(cie_l)\n",
    "    \n",
    "    combined[(cie_l == 1) | (cie_b == 1)] = 1\n",
    "    \n",
    "    return np.dstack((combined, combined*0, combined*0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image):\n",
    "    \n",
    "    # Convert image from float32 to uint8\n",
    "    image = image.astype(np.float32)\n",
    "    image = image/255\n",
    "\n",
    "        \n",
    "    # Send the image for processing to combined_image()\n",
    "    comb = combined_image(image)\n",
    "\n",
    "    # Convert the image back to uint8\n",
    "    weighted = cv2.addWeighted(image, 0.5, comb, 1, 0)\n",
    "    uint_img = cv2.convertScaleAbs(weighted * 255)\n",
    "    \n",
    "#     uint_img = cv2.cvtColor(uint_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    return uint_img\n",
    "\n",
    "    \n",
    "'''problem_frames/9.png'''\n",
    "\n",
    "img = cv2.imread('problem_frames/14.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "proc = process_images(img)\n",
    "    \n",
    "cv2.imshow('img', proc)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   2%|â–         | 3/125 [00:00<00:07, 15.75it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/project_video.mp4.\n",
      "Moviepy - Writing video test_videos_output/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/project_video.mp4\n",
      "CPU times: user 44 s, sys: 1.14 s, total: 45.1 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(20,25)\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_images) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenvpi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
