{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points like (0,0,0), (1,0,0), (2,0,0), ...,(6,5,0)\n",
    "objpts = np.zeros((6*9, 3), np.float32)\n",
    "# Get the meshgrid points one by one and replace them in the x and y \n",
    "# coordinates of the object points\n",
    "objpts[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "def get_cam_params():\n",
    "    '''\n",
    "    Gets undistortion parameters for the camera, based on a set of calibration images\n",
    "    \n",
    "    Takes all the images in the `camera_cal` folder and finds the undistortion coefficients based\n",
    "    on the images.\n",
    "    The calibration matrix and dist parameters are the only things we will use later on.\n",
    "    \n",
    "    :return: Camera parameters, namely `mtx` and `dist`\n",
    "    \n",
    "    '''\n",
    "    images = glob.glob('camera_cal/*.jpg')\n",
    "\n",
    "    for idx, frame_name in enumerate(images):\n",
    "        image = cv2.imread(frame_name)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        if ret == True:\n",
    "            objpoints.append(objpts)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "\n",
    "            cv2.imshow('image', image)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "    test_img = cv2.imread('camera_cal/calibration4.jpg')\n",
    "    imshape = test_img.shape\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (imshape[1], imshape[0]), None, None)\n",
    "\n",
    "    result = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('camera_cal/test_undist.jpg', result)\n",
    "    \n",
    "    return mtx, dist\n",
    "    \n",
    "    \n",
    "def store_cam_params(mtx, dist):\n",
    "    '''\n",
    "    Stores the two camera parameters as a binary file for later use\n",
    "    \n",
    "    :param mtx: Transformation matrix to store in the pickle file\n",
    "    :param dist: Parameter containing distances, to store in the pickle file\n",
    "    \n",
    "    '''\n",
    "    pkl = {}\n",
    "    pkl[\"mtx\"] = mtx\n",
    "    pkl[\"dist\"] = dist\n",
    "    pickle.dump( pkl, open( \"camera_cal/camera_param_pickle.p\", \"wb\" ) )\n",
    "    \n",
    "def load_pickle():\n",
    "    '''\n",
    "    Loads the camera parameters from the pickle file previously stored.\n",
    "    \n",
    "    :return: Dictionary containg the data in pickle\n",
    "    \n",
    "    '''\n",
    "    infile = open(\"camera_cal/camera_param_pickle.p\",'rb')\n",
    "    new_dict = pickle.load(infile)\n",
    "    infile.close()\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_select(image, thresh=(0, 255), channel='l'):\n",
    "    '''\n",
    "    Masks the given channel of the CIE Lab image using the thresholds given.\n",
    "    \n",
    "    :param image: Image to be converted in CIE Lab and then thresholded\n",
    "    :param thresh: Tuple containing upper and lower threshold values\n",
    "    :param channel: Character indicating the channel to work on\n",
    "    :return: The thresholded binary image\n",
    "    \n",
    "    '''\n",
    "    # Convert the image to the CIE Lab colorspace\n",
    "    cie_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "#     cie_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Select the appropriate channel for processing\n",
    "    if channel == 'l':\n",
    "        ch = 0\n",
    "        channel = \"CIE L\"\n",
    "    elif channel == 'a':\n",
    "        ch = 1\n",
    "        channel = \"CIE A\"\n",
    "    elif channel == 'b':\n",
    "        ch = 2\n",
    "        channel = \"CIE B\"\n",
    "\n",
    "    layer = cie_lab[:, :, ch]\n",
    "    \n",
    "    # The L channel has an automatic thresholding mode, regardles of the input thresholds\n",
    "    if channel == 'CIE L':\n",
    "        \n",
    "        a = 39.20193\n",
    "        b= 5.121302\n",
    "        c = 42.48095\n",
    "        d = 88.16211\n",
    "\n",
    "        avg = np.average(layer[420:,:])\n",
    "        \n",
    "        thresh0 = d + (a - d) / (1 + (avg / c) ** b)\n",
    "        thresh0 = thresh0\n",
    "        thresh1 = 100\n",
    "\n",
    "    else:\n",
    "        thresh0 = thresh[0]\n",
    "        thresh1 = thresh[1]\n",
    "        \n",
    "    # Return a binary image of threshold result\n",
    "    mask = np.zeros_like(layer)\n",
    "    \n",
    "    mask[(layer >= thresh0) & (layer <= thresh1)] = 1\n",
    "    \n",
    "    \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_filters(image):\n",
    "    '''\n",
    "    Combine different filters in order to get the lanes from the image.\n",
    "    \n",
    "    :param image: Image to process\n",
    "    :return: Binary mask of the image with everything but the lane lines removed\n",
    "    \n",
    "    '''\n",
    "    # Parameters for the bilateral filter\n",
    "    diam = 9\n",
    "    sig_col = 13\n",
    "    sig_sp = 31\n",
    "\n",
    "    \n",
    "    blur_filter = cv2.bilateralFilter(image, d=diam, sigmaColor=sig_col, sigmaSpace=sig_sp)\n",
    "\n",
    "    # Take two masked images, applying different thresholds on each of them\n",
    "    # The cie_l image automatically calculates it's thresholds\n",
    "    cie_l = lab_select(blur_filter)\n",
    "    cie_b = lab_select(blur_filter, (18, 100), \"b\")\n",
    "    \n",
    "    # Combine the two images in a single one\n",
    "    combined = np.zeros_like(cie_l)\n",
    "    combined[(cie_l == 1) | (cie_b == 1)] = 1\n",
    "    \n",
    "#     return np.dstack((combined, combined, combined))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_image(image):\n",
    "    '''\n",
    "    Convert the image to another format, apply the filtering function and convert it back to the original format\n",
    "    \n",
    "    :param image: Image to process\n",
    "    :return: Processed image of type uint8\n",
    "    \n",
    "    '''\n",
    "    # Convert image from float32 to uint8\n",
    "    image = image.astype(np.float32)\n",
    "    image = image/255\n",
    "\n",
    "        \n",
    "    # Send the image for processing to combined_image()\n",
    "    comb = combined_filters(image)\n",
    "\n",
    "    # Convert the image back to uint8\n",
    "#     weighted = cv2.addWeighted(image, 0.5, comb, 1, 0)\n",
    "    \n",
    "    weighted = comb\n",
    "    uint_img = cv2.convertScaleAbs(weighted * 255)\n",
    "    \n",
    "    return uint_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def undistort(image, mtx, dist):\n",
    "    ''' Undistorts given image based on the parameters `mtx` adn `dist`'''\n",
    "    \n",
    "    result = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_perspective(image, mode=\"direct\"):\n",
    "    '''\n",
    "    Transform the image in bird's eye view or from bird's eye view back to normal\n",
    "    \n",
    "    :param image: Image to process\n",
    "    :mode: String indicating if the transformation is a direct or inverse one\n",
    "    :return: Perspective transformed image\n",
    "    \n",
    "    '''\n",
    "    height = image.shape[0]\n",
    "    width  = image.shape[1]\n",
    "    \n",
    "    # Set the horizontal boundaries of the roi to be warped\n",
    "    y1 = 450\n",
    "    y2 = 690\n",
    "\n",
    "    coef = 300\n",
    "    up = 33\n",
    "\n",
    "    pts1 = np.float32([[587 - up, y1], [692 + up,  y1], [1068 + coef,      y2], [230 - coef,   y2]])\n",
    "    pts2 = np.float32([[0,    0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "    if mode == \"direct\":\n",
    "        M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(pts2, pts1)\n",
    "\n",
    "    # Transform the image\n",
    "    dst = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "\n",
    "    # Apply this operations on a warped binary image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:, :], axis=0)\n",
    "    # Create an output image, to visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # print(leftx_base, \" \", rightx_base)\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set width of windows +/- margin\n",
    "    margin = 100\n",
    "    # Minimum number of pixels to recenter image\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on the parameters above\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    # NOTE: np.nonzero() returns the indices of the nonzero points in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    \n",
    "    # Split the array of nonzero points in two arrays that contain only the x and y \n",
    "    # coordinates respectively\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Set the current position to be the base of the first window. The position will be \n",
    "    # updated for each window in `nwindows`\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "\n",
    "        win_xleft_low   = leftx_current - margin\n",
    "        win_xleft_high  = leftx_current + margin\n",
    "        win_xright_low  = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low),\n",
    "                      (win_xleft_high, win_y_high), (0,255,0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low),\n",
    "                      (win_xright_high, win_y_high), (0,255,0), 2)\n",
    "\n",
    "        # TODO: Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = np.array(np.nonzero((win_xleft_low <= nonzerox) & (nonzerox < win_xleft_high) &\n",
    "                                             (win_y_low <= nonzeroy) & (nonzeroy < win_y_high)))\n",
    "        # good_left_inds = nonzerox[(win_xleft_low < nonzerox) & (nonzerox < win_xleft_high) &\n",
    "        #                           (win_y_low < nonzeroy) & (nonzeroy < win_y_high)]\n",
    "        good_right_inds = np.array(np.nonzero((win_xright_low <= nonzerox) & (nonzerox < win_xright_high) &\n",
    "                                              (win_y_low <= nonzeroy) & (nonzeroy < win_y_high)))\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds[0])\n",
    "        right_lane_inds.append(good_right_inds[0])\n",
    "\n",
    "        # TODO: If you found > minpix pixels, recenter window\n",
    "        # (`right` or `leftx_current`) on their mean position\n",
    "\n",
    "        if (np.size(good_right_inds) > minpix):\n",
    "            rightx_current = np.int(np.average(nonzerox[good_right_inds], axis=1))\n",
    "\n",
    "        if (np.size(good_left_inds) > minpix):\n",
    "            leftx_current = np.int(np.average(nonzerox[good_left_inds], axis=1))\n",
    "            # print(leftx_current)\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    \n",
    "    ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "    \n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TODO: Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "#     left_fit = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "#     right_fit = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    \n",
    "#     right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix , 2)\n",
    "    \n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    # np.linspace() is similar to range(first, last, values), with the difference that the last parameters specifies the\n",
    "    # number of values to be generated, not the step\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "\n",
    "    # Generate the x coordinates for each of the y coordinates of the fitted function\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    except:\n",
    "        print(\"The function failed to fit a line!\")\n",
    "\n",
    "    ### Visualization\n",
    "    # Colors in the left an right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    plt.imshow(out_img)\n",
    "\n",
    "    return out_img, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(left_fit_cr, right_fit_cr):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = 719\n",
    "    \n",
    "    left_fit_cr[0] = left_fit_cr[0] * (xm_per_pix/(ym_per_pix ** 2))\n",
    "    left_fit_cr[1] = left_fit_cr[1] * (xm_per_pix/ym_per_pix)\n",
    "    \n",
    "    right_fit_cr[0] = right_fit_cr[0] * (xm_per_pix/(ym_per_pix ** 2))\n",
    "    right_fit_cr[1] = right_fit_cr[1] * (xm_per_pix/ym_per_pix)\n",
    "\n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad =  ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** (3/2)) / np.abs(2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** (3/2)) / np.abs(2 * right_fit_cr[0])\n",
    "\n",
    "    return left_curverad, right_curverad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_images/7.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Warping works'''\n",
    "\n",
    "params_dict = load_pickle()\n",
    "\n",
    "image = cv2.imread('test_images/2.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "undist = undistort(image, params_dict[\"mtx\"], params_dict[\"dist\"])\n",
    "warped = warp_perspective(undist)\n",
    "\n",
    "# res = np.vstack((image, undist))\n",
    "\n",
    "# res = cv2.resize(res, (res.shape[1]//2,res.shape[0]//2))\n",
    "cv2.imshow('res', warped)\n",
    "cv2.waitKey(0)\n",
    "# cv2.imwrite('output_images/camera_cal_before.png', image)\n",
    "# cv2.imwrite('output_images/camera_cal_after.png', undist)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3894.919466879589, 1593.2229302728028)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = cv2.imread('test_images/7.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "''' Camera undistortion works '''\n",
    "\n",
    "''' IMportant code lines below'''\n",
    "# mtx, dist = get_cam_params()\n",
    "# store_cam_params(mtx, dist)\n",
    "params_dict = load_pickle()\n",
    "\n",
    "undist = undistort(image, params_dict[\"mtx\"], params_dict[\"dist\"])\n",
    "binary = filtered_image(undist)\n",
    "warped = warp_perspective(binary)\n",
    "fit, left_fit, right_fit    = fit_polynomial(warped)\n",
    "\n",
    "radius = measure_curvature_real(left_fit, right_fit)\n",
    "\n",
    "print(radius)\n",
    "\n",
    "cv2.imshow('res', fit)\n",
    "# cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwarped = warp_perspective(fit, \"inverse\")\n",
    "\n",
    "cv2.imshow('res', unwarped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Facui lucrurile cerute mai jos '''\n",
    "\"\"\"\n",
    "Ramane pe maine de implementat clasa Lane, cu functionalitatea ei.\n",
    "Am vrut sa pun conversia din pixeli in metri mai sus, in polyfit, dar n-am putut, din cauza ca\n",
    "np.polyfit e utilizata si pentru desenarea benzii pe imagine, iar daca o convertesc in metri, e bai, \n",
    "liniile de fit ies din imagine.\n",
    "Am pus conversia doar la calcularea razei, dar banuiesc ca rezultatele nu-s bune. :)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Coming up....\n",
    "\n",
    "    - bird's eye view\n",
    "    - indentify lanes (customize the aalgorithm a little)\n",
    "    - gather lane points (start with box, continue from prior)\n",
    "                          check for boxes touching edge\n",
    "    - fit polynomial on lanes\n",
    "    - calculate the radius\n",
    "    \n",
    "    \n",
    "    - implement a Lane class \n",
    "        (with history, averaging over n previous values, outlier rejection - based on \n",
    "        polynomial parameters variation or radius variation)\n",
    "        + reset method for deeply flawed measurements\n",
    "        \n",
    "    - apply all of it on the video\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\").subclip(20,25)\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_images) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenvpi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
